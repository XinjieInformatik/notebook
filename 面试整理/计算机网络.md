# 计算机网络
待整理: https://github.com/Snailclimb/JavaGuide/blob/master/docs/network/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.md
## 计算机网络体系结构
参考 https://github.com/CyC2018/CS-Notes/blob/master/notes/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%20-%20%E7%9B%AE%E5%BD%95.md

![20200705_135225_93](assets/20200705_135225_93.png)

1. 五层协议
- 应用层：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等协议。数据单位为报文。
- 传输层：为进程提供通用数据传输服务。由于应用层协议很多，定义通用的传输层协议就可以支持不断增多的应用层协议。包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。
- 网络层：为主机提供数据传输服务。而传输层协议是为主机中的进程提供数据传输服务。网络层把传输层传递下来的报文段或者用户数据报封装成分组。
- 数据链路层 ：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的主机提供数据传输服务。数据链路层把网络层传下来的分组封装成帧。
- 物理层：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

2. OSI
其中表示层和会话层用途如下：
- 表示层：数据压缩、加密以及数据描述，这使得应用程序不必关心在各台主机中数据内部格式不同的问题。
- 会话层：建立及管理会话。
五层协议没有表示层和会话层，而是将这些功能留给应用程序开发者处理。

3. TCP/IP
它只有四层，相当于五层协议中数据链路层和物理层合并为网络接口层。
TCP/IP 体系结构不严格遵循 OSI 分层概念，应用层可能会直接使用 IP 层或者网络接口层。

4. 数据在各层之间的传递过程
在向下的过程中，需要添加下层协议所需要的首部或者尾部，而在向上的过程中不断拆开首部和尾部。
路由器只有下面三层协议，因为路由器位于网络核心中，不需要为进程或者应用程序提供服务，因此也就不需要传输层和应用层。


### 三次握手
第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。

第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。

第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。

经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的, 之后就可以正常通信了。
- 防止历史连接的建立
- 确保双方的初始序列号能被可靠的同步

第三次握手是可以携带数据的，前两次握手是不可以携带数据的
TCP 的连接状态查看，在 Linux 可以通过 netstat -napt

### 四次挥手
TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，等到发送完了所有的数据后，会发送一个FIN段来关闭此方向上的连接。接收方发送ACK确认关闭连接。
参考: https://zhuanlan.zhihu.com/p/53374516

![20200703_105922_12](assets/20200703_105922_12.png)

![20200804_223736_99](assets/20200804_223736_99.png)

关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。

为什么 TIME_WAIT 等待的时间是 2MSL？
被动关闭的服务端无需任何wait time，直接释放资源。客户端需要等待2MSL确保服务端收到ACK,如果服务端没收到会重新发FIN报文. 去向ACK报文最大存活时间（MSL) + 来向FIN报文的最大存活时间(MSL), 恰好是2MSL, MSL 报文最大生存时间.


### 什么是面向有连接型和面向无连接型？
面向有连接型传输: 包括会话建立、传输数据和会话断开，此外还包括保证传输可靠性的各种措施，比如超时重传、流量控制等，常见的面向有连接传输有TCP；
面向无连接型传输: 仅提供基本的传输数据的功能，即使接收端不存在，发送端也能发送数据包，常见的面向无连接传输有UDP、IP。

### TCP UDP 区别
传输控制协议 TCP（Transmission Control Protocol）
是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。
用户数据报协议 UDP（User Datagram Protocol）
是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。

![20200703_110857_27](assets/20200703_110857_27.png)

### TCP对应的应用层协议有哪些？UDP对应的应用层协议有哪些？
TCP对应的典型的应用层协议：
- FTP：文件传输协议；
- SSH：远程登录协议；
- HTTP：web服务器传输超文本到本地浏览器的超文本传输协议。

UDP对应的典型的应用层协议：
- DNS：域名解析协议；
- TFTP：简单文件传输协议；
- SNMP：简单网络管理协议。

### TCP 拥塞控制
计算机网络都处在一个共享的环境，在通信开始时如果立即把大量数据注入到网络，可能会引起网络阻塞，甚至带来网络瘫痪。TCP为了防止该问题的出现，采用了拥塞控制的策略，常见的拥塞控制策略有慢启动、拥塞避免、快重传与快恢复.
以慢启动为例, 在通信开始时，定义一个“拥塞窗口”，窗口大小为1，意思是开始时只发送一个分组，之后每收到一个确认回执（ACK），拥塞窗口的大小就加1（即逐渐增大窗口大小），发送端在发送数据时，将拥塞窗口的大小与接收端流量控制窗口的大小作比较，取二者中较小的值，然后实际发送的数据量比这个最小值还要小。

### 什么是TCP 粘包、拆包？
1. 接收端正常收到两个数据包，即没有发生拆包和粘包的现象。
2. 接收端只收到一个数据包，但是这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。
3. 接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。

### 为什么会发生 TCP 粘包、拆包？
- 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包。
- 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。
- 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包。
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。

### 粘包、拆包解决办法
由于 TCP 本身是面向字节流的，无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，解决方案归纳如下：
- 消息定长：发送端将每个数据包封装为固定长度（不够的可以通过补 0 填充），这样接收端每次接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
- 设置消息边界：服务端从网络流中按消息边界分离出消息内容。在包尾增加回车换行符进行分割，例如 FTP 协议。
- 将消息分为消息头和消息体：消息头中包含表示消息总长度（或者消息体长度）的字段。

### http和https
http (HyperText Transfer Protocol) 协议是应用层的协议，超文本传输协议，是客户端和服务端相互通信时将信息以http报文的形式传输。
HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。

早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手）. 为了解决上述 TCP 连接问题，HTTP/1.1 提出了长连接的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。
HTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是 前面的回应特别慢，后面就会有许多请求排队等着。这称为「队头堵塞」。

HTTP/2 协议是基于 HTTPS 的. HTTP/2 相比 HTTP/1.1 性能上的改进:
- HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的分。这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
- HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。
- HTTP/2 的数据包不是按顺序发送的，因此，必须要对数据包做标记，指出它属于哪个回应。每个请求或回应的所有数据包，称为一个数据流（Stream）。每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数. 客户端还可以指定数据流的优先级。服务器优先响应优先级高的请求。
- HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。

- HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了
- HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。
这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP.

UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。


摘要算法用来实现完整性，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。

HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式：
- 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。
- 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。
采用「混合加密」的方式的原因：
- 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
- 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢

http协议的缺点:
- 通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏。
- 不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多。
- 无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告。

https可以简单的理解为：https = http + 加密 + 认证 + 完整性保护。


https协议改进
- 加密。https协议通过SSL或者TLS协议将报文内容进行加密，client端进行加密，server端进行解密。
- 认证。通过值得信赖的第三方机构颁布证书，即可确认通信双方的身份。客户端持有证书即可完成客户端身份的确认，客户端通信前会查看服务端的证书。
- 完整性保护。可以通过MD5等散列码进行通信内容的校验。

参考: https://www.nowcoder.com/discuss/379081?source_id=profile_create&channel=666

todo: HTTPS密钥交换过程，CA信任链

CA信任链
通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。
![20200804_212521_66](assets/20200804_212521_66.png)

### 常见的http动词
- GET: 从服务器获取资源
- POST: 在服务器新建资源
- PUT: 在服务器更新资源
- DELETE: 在服务器删除资源
- HEAD: 获取资源的元数据
- OPTIONAL: 查询对指定的资源支持的方法

### 从URL输入到页面展现发生什么
1. 根据域名到DNS中找到IP
2. 根据IP建立TCP连接(三次握手)
3. 发起http请求
4. 服务器响应http请求
5. 浏览器解析HTML代码并请求html中的静态资源（js,css）
6. 关闭TCP连接（四次挥手）
7. 浏览器渲染页面
