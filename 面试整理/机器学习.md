# 机器学习

### FM
线性回归模型
![20200712_102107_23](assets/20200712_102107_23.png)
可见上式中各个特征分量之间是独立的,如果进一步考虑特征之间的交互关系,可将线性回归写成
![20200712_102357_25](assets/20200712_102357_25.png)
上述公式的问题是,对于观察样本中未出现过的交互的特征分类,无法估计w矩阵中的相应参数.这在稀疏的数据场景还是挺常见的. 因此FM提出用(n,k)维的v, $V V^T$ 对w矩阵分解替代. 可以看到长度为k的v相当于对原始长度为n的特征做了embbeding.
时间复杂度O(kn).
参考: https://www.cnblogs.com/pinard/p/6370127.html

### ROC 曲线 AUC 含义
ROC曲线: X轴-FPR(false positive rate)，Y轴-TPR(true positive rate)
TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。
TPR = TP / (TP + FN)
FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。
FPR = FP / (FP + TN)

设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。

AUC: 若随机抽取一个阳性样本和一个阴性样本，分类器正样本的预测概率大于负样本的预测概率之几率.
AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。
mAP受正负样本分布影响明显,AUC几乎不变
```python
def AUC(label, pre):
    # label = [1,0,0,0,1,0,1,0]
    # pre = [0.9, 0.8, 0.3, 0.1, 0.4, 0.9, 0.66, 0.7]
    pos = [i for i in range(len(label)) if label[i] == 1]
    neg = [i for i in range(len(label)) if label[i] == 0]
    auc = 0
    # AUC的含义就是所有穷举所有的正负样本对，
    # 如果正样本的预测概率大于负样本的预测概率，+１
    # 如果正样本的预测概率等于负样本的预测概率，+0.5
    # 如果正样本的预测概率小于负样本的预测概率，+0
    for i in pos:
        for j in neg:
            if pre[i] > pre[j]:
                auc += 1
            elif pre[i] == pre[j]:
                auc += 0.5

    return auc / (len(pos)*len(neg))
```
例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。

### 生成模型与判别模型有什么区别
生成模型学习联合概率分布$p(x,\theta)$，而判别模型学习条件概率分布$p(x|\theta)$

### L1, L2 正则化
L1正则化:将权重的绝对值之和加入到损失函数
L2正则化:将权重的平方值之和加入到损失函数,减小模型复杂度

L1正则化有特征选择的效果,得到稀疏化的权重
L2正则化同样有减小权重的效果,最终得到平滑的权重

其实L1,L2正则化可以看作是为原始损失函数添加了约束,使得权重|w| < C, ||w||^2 < C. (以L1为例)通过拉格朗日方程,可以把损失函数与约束整理为 $L_0 + \lambda(|w|-C)$,因为是优化问题可以忽略掉常数项C, 得到最终损失函数的形式$min (L_0 + \lambda |w|)$. 因为是不等式约束, 根据KKT条件, 如果原始损失函数L0的等高线在约束域外, 最优解就是等高线与约束域的切点.(如果在约束域内,不用理会约束域).其实拉格朗日方程能融合约束与损失函数是基于梯度方向一致性的假设(要想让目标函数f(x,y)的等高线和约束相切，则他们切点的梯度一定在一条直线上(f和g的斜率平行)).

L1 更容易产生稀疏解的三种解释.
1. 解空间形状
![20200711_230638_28](assets/20200711_230638_28.png)
图中以二个权重为例,L2正则化定义了圆形(w^2),L1定义了菱形(|w|).蓝色的等高线是原始损失函数的. 等高线圆心在约束域外,根据KKT条件,等高线与约束域的切点为极值点.对于L2约束域,只有一个梯度方向会导致极值点落在权重为零的位置.对于L1约束域,许多梯度方向都会导致极值点落在权重为零的位置.因此L1更容易产生稀疏解.

2. 损失函数
参数更新公式 $ w = w - lr \frac{\partial{L}}{\partial{w}}$
$ L_0 + \lambda |w| $ --L1损失函数求导得-- $ \frac{\partial{L_0}}{\partial{w}} + sign(\lambda)$
$ L_0 + \lambda w^2 $ --L2损失函数求导得-- $ \frac{\partial{L_0}}{\partial{w}} + 2\lambda w$
    - 当$\frac{\partial{L_0}}{\partial{w}}$梯度较小时,L1的梯度为$sign(\lambda)$ 主导梯度更新的方向,若w>0,向负方向更新$lr \lambda$(假设L0梯度很小可忽略);若w<0,向正方向更新$lr \lambda$. 因此w总是向0点方向更新,趋向于取得零值.
    - 当$\frac{\partial{L_0}}{\partial{w}}$梯度较小时,L2的梯度为$2\lambda w$,梯度值也较小,L2的梯度也同L1一样,想让w的更新方向向零点靠近,但是由于此时w变小,相对于L0的偏导,无法主导梯度更新的方向.因此L2趋向与取得较小而分散的权重

3. 拉普拉斯先验 与 高斯先验 分布
$$ p(\theta|x) = \frac{p(x|\theta)p(\theta)}{p(x)}$$
其中$p(\theta|x)$是贝叶斯概率, $p(x|\theta)$是似然函数, $p(\theta)$是先验概率分布. $p(x)$是固定的只与样本有关, 因此重点看分子.
其中$p(\theta)$是先验分布,如果是拉普拉斯分布,取log后正好是L1 |w| 的形式,相当于在原来似然函数上加上了L1正则化. 拉普拉斯分布见下图,0附近概率密度最大,而且有平顶,容易停留,因此容易产生稀疏解. 高斯分布会产生L2 $w^2$的形式.

贝叶斯概率与最大后验概率的区别,贝叶斯认为先验是一个分布,最大后验概率认为先验是一个常量.

![20200712_012035_41](assets/20200712_012035_41.png)

注意最大似然估计假设样本之间是独立的,因此最大化总体的似然估计可以转化成最大化每个个体似然估计的连乘,取log变成累加,就可以推导出交叉熵公式.

MSE假设分布符合高斯分布,因此个体连乘,取log后就是平方项的累加形式.


### 距离公式
欧式距离, 闵可夫斯基距离(p次方求和开p根号,是欧式距离的一般形式), 曼哈顿距离, 汉明距离, 余弦距离(1-cos)两向量夹角余弦值
除了余弦距离外,以上都属于严格的距离公式,即满足1.正定性 2.对称性 3.三角距离公式

### KNN
要找到k个最近的邻居来做预测，那么我们只需要计算预测样本和所有训练集中的样本的距离，然后计算出最小的k个距离即可，接着多数表决，很容易做出预测。这个方法的确简单直接，但计算量大。
#### KD树
- KD树建树采用的是从m个样本的n维特征中，分别计算n个特征的取值的方差，用方差最大的第k维特征𝑛𝑘来作为根节点。对于这个特征，我们选择特征𝑛𝑘的取值的中位数𝑛𝑘𝑣对应的样本作为划分点，对于所有第k维特征的取值小于𝑛𝑘𝑣的样本，我们划入左子树，对于第k维特征的取值大于等于𝑛𝑘𝑣的样本，我们划入右子树，对于左子树和右子树，我们采用和刚才同样的办法来找方差最大的特征来做更节点，递归的生成KD树。
- 生成KD树以后，就可以去预测测试集里面的样本目标点了。对于一个目标点，我们首先在KD树里面找到包含目标点的叶子节点。以目标点为圆心，以目标点到叶子节点样本实例的距离为半径，得到一个超球体，最近邻的点一定在这个超球体内部。然后返回叶子节点的父节点，检查另一个子节点包含的超矩形体是否和超球体相交，如果相交就到这个子节点寻找是否有更加近的近邻,有的话就更新最近邻。如果不相交那就简单了，我们直接返回父节点的父节点，在另一个子树继续搜索最近邻。当回溯到根节点时，算法结束，此时保存的最近邻节点就是最终的最近邻。
参考: https://www.cnblogs.com/pinard/p/6061661.html

### 特征工程
1. 过滤法
1.1 方差选择法: 如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用. 计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。
1.2 相关系数法: Pearson 相关系数定义为两个变量之间的协方差和标准差的商, 可以理解为无量纲化后的协方差, 计算公式如下
![20200712_161334_52](assets/20200712_161334_52.png)
1.3 卡方检验: 检验某个特征分布和输出值分布之间的无关性(1-无关性就是相关性). 1.首先基于真实分布,我们可以得到两个变量的统计表格. 2.因为无法排除两个遍历分布的差异是否由抽样差异决定的,所以我们先做无关性假设,计算出理论值的分布表格.卡方(x^2)的计算$\sum \frac{(A-T)^2}{T}$ 其中T为理论值, A为真实值. 3.根据自由度查询卡方分布的临界值表(自由度V=(行数-1)(列数-1)), 可得到两变量无关的概率.
1.4 互信息，即从信息熵的角度分析各个特征和输出值之间的关系, 互信息值越大，说明该特征和输出值之间的相关性越大，越需要保留.
![20200712_163809_24](assets/20200712_163809_24.png)

2. 包装法
递归消除特征法: 递归消除特征法使用一个机器学习模型来进行多轮训练，每轮训练后，消除若干权值系数的对应的特征，再基于新的特征集进行下一轮训练。

3. 嵌入法
机器学习的方法来选择特征，但是它和RFE的区别是它不是通过不停的筛掉特征来进行训练，而是使用的都是特征全集。最常用的是使用L1正则化和L2正则化来选择特征, 或者决策树的特征重要程度.

寻找高级特征常用方法：
- 特征加和, 特征之差, 特征乘积, 特征除商
- 基于业务挖掘高级特征, 更有表现力的特征, 挖掘模式, 行为习惯等.

参考: https://segmentfault.com/a/1190000003719712
https://www.zhihu.com/question/28641663
https://www.cnblogs.com/pinard/p/9032759.html

### 假设检验
#### Z检验 T检验
Z检验是用于大样本(>30),总体方差已知的均值差异检验.
比较总体的均值$\bar X$与某个常数$\mu_0$是否有显著性的差异,公式如下. $\bar{X}$是样本均值,$\mu$是总体均值,$\sigma$是总体标准差,n是样本容量.
- 单个样本的Z检验
$$ Z = \frac{\bar{X}-\mu_0}{\sqrt\frac{\sigma^2}{{n}}} $$
如果是检验两组样本间平均值的差异, 公式如下 (检验时假设两个总体的均值相等u1-u2=0)
- 两个样本的均值的Z检验
$$ Z = \frac{\bar{X}_1-\bar{X}_2}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}} $$

T检验是用于小样本,总体方差未知的均值差异检验.
- 单个样本的T检验
$\bar X$ 为样本均值, $\mu_0$为总体均值,$\sigma$为样本标准差,n为样本数.
$$ T = \frac{\bar{X}-\mu_0}{\sqrt\frac{\sigma^2}{{n}}} $$

- 两个配对样本t检验($\bar d$为配对样本差值的均值)
![20200712_224159_61](assets/20200712_224159_61.png)
![20200712_224407_12](assets/20200712_224407_12.png)

- 两个独立样本均值的T检验
异方差独立样本T检验
$$ T = \frac{\bar{X}_1-\bar{X}_2}{\sqrt{\frac{\sigma_1^2}{n_1}+\frac{\sigma_2^2}{n_2}}} $$
等方差独立样本T检验
![20200712_223758_39](assets/20200712_223758_39.png)

- 卡方检验: 检验两个变量之间有没有关系
- F检验: 检验两个正态随机变量的总体方差是否相等

### A/B test
一部分用户使用原方案A（对照组），同时另一部分用户使用新方案B（试验组），对比不同方案下转化率、点击量、留存率等指标，以判断不同方案的优劣并进行决策。
A/B测试中是用对照组和试验组这两个样本的数据来对两个总体是否存在差异进行检验，所以其本质是使用假设检验中的独立样本t检验 。

1. 测试时长如何设定？
测试的时长不宜过短。用户进入到新方案中，很可能因为好奇而表现得更加活跃，但随着时间的推移，逐渐趋于冷静，数据表现回到本该有的水平，如果实验观察期设置的过早，则容易得出错误的结论。适应期的长短通常以足量用户参与试验后的2到3天为宜。适应期过后的试验时间长短除了需要考察样本量外，还需要参考用户的行为周期，譬如说电商用户的购买行为有较强的周期规律，周末的购买量与工作日会有显著差异，这时测试的周期需要能够覆盖一个完整的周期，也就是应该大于1周。

但是测试时间也不宜太长，因为A/B测试是对线上多个版本的测试，这也就意味着线上系统需要同时维护多个可用的版本，长时间的A/B测试无疑加大了系统的复杂性。

2. 确定实验所需样本数量
H0 = A、B没有差异
H1 = A、B存在差异
统计功效power是说拒绝H0后接受H1假设概率。直观上说，AB即使有差异，也不一定能被你观测出来，必须保证一定的条件（比如样本要充足）才能使你能观测出统计量之间的差异；

3. 如何用户 实验组/对照组 分组
1.样本互相独立 2.分组的用户群在各维度的特征都应相似

4. A/B测试只能同时测试2个方案吗？
A/B测试不是只能测试A方案和B方案，实际上一个测试可以包含A/B/C/D/E/……多个版本，但是要保证是单变量的测试，比如按钮的颜色---赤/橙/黄/绿/青/蓝/紫，那么这七个方案可以同时做A/B测试，但如果某方案在旁边新增了另一个按钮，即便实验结果产生了显著差异，我们也无法判断这种差异的成因究竟是什么。

5. 什么是A/A测试？
A/A测试将分给原始版本的流量再次划分，分出的两组流量分别给两个相同的原始版本进行测试。A/A测试用来评估两个实验组是否是处于相同的水平，是为了测试埋点、分流、实验统计的正确性，增加A/B测试的结论可信度。如果AA实验的结果不存在显著差异，那么可以认为实验结果是有效的，进而可以对新老版本的实验结果进行进一步的判断。

参考: https://www.cnblogs.com/HuZihu/p/11178068.html
https://zhuanlan.zhihu.com/p/38471891

### EM算法推导
