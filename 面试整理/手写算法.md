# 手写算法
### 手写IoU
```python
import numpy as np
def iou_calculate(bbox1, bbox2):
    """
    Args:
      bbox1: (N, 4) (xmin, ymin, xmax, ymax)
      bbox2: (M, 4) np.array
    Returns:
      iou: (N,M)
    """
    area1 = (bbox1[..., 2] - bbox1[..., 0]) * (bbox1[..., 3] - bbox1[..., 1]) # (N,)
    area2 = (bbox2[..., 2] - bbox2[..., 0]) * (bbox2[..., 3] - bbox2[..., 1]) # (M,)
    lt = np.maximum(bbox1[:, None, :2], bbox2[:, :2]) # (N, M, 2)
    rb = np.minimum(bbox1[:, None, 2:], bbox2[:, 2:]) # (N, M, 2)
    inter = np.maximum(0, rb - lt) # (N, M, 2)
    inter_area = inter[..., 0] * inter[..., 1] # (N, M)
    union_area = area1[:, None] + area2 - inter_area # (N, M)
    iou = inter_area / union_area
    return iou
```

### 手写NMS
```python
def nms(bboxes, iou_thresh):
    """
    Args:
      bboxes: after score. np.array. (N, 6) [xmin, ymin, xmax, ymax, score, class]
      iou_thresh: float
    Returns:
      bboxes_nms: np.array. (N', 6) [xmin, ymin, xmax, ymax, score, class]
    """
    classes = bboxes[:, 5] # (N,)
    unique_classes = set(classes)
    bboxes_nms = []
    for cls in unique_classes:
        mask = classes == cls # (N,)
        cls_bboxes = bboxes[mask] # (M, 6)
        # nms in each class
        x1, y1 = cls_bboxes[:, 0], cls_bboxes[:, 1] # (M,)
        x2, y2 = cls_bboxes[:, 2], cls_bboxes[:, 3]
        scores = cls_bboxes[:, 4] # (M,)
        areas = (x2 - x1) * (y2 - y1) # (M,)
        order = scores.argsort()[::-1] # (M,)
        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            x1_max = np.maximum(x1[i], x1[order[1:]]) # (1,), (M-1,) -> (M-1,)
            y1_max = np.maximum(y1[i], y1[order[1:]])
            x2_min = np.minimum(x2[i], x2[order[1:]])
            y2_min = np.minimum(y2[i], y2[order[1:]])
            w = np.maximum(0, x2_min - x1_max) # (M-1,)
            h = np.maximum(0, y2_min - y1_max)
            inter_area = w * h # (M-1,)
            union_area = areas[i] + areas[order[1:]] - inter_area # (1,), (M-1,) -> (M-1,)
            iou = inter_area / union_area # (M-1,)
            keep_index = np.where(iou <= iou_thresh)[0]
            order = order[keep_index + 1]
        keep_bboxes = cls_bboxes[keep]
        bboxes_nms.append(keep_bboxes)
    bboxes_nms = np.vstack(bboxes_nms)
    return bboxes_nms
```

### focal loss
$$ \text{FL}(p_t) = -a_t(1-p_t)^\gamma log(p_t) $$
p_t = p if y == 1 else (1-p)
由于正负样本数目间悬殊的差距，会造成训练初期不稳定，focal loss提出网络权重初始化的问题，让模型训练初期正样本的预测更少，负样本的更多，获得一个更稳定更小的初期的训练loss。网络class head最后一层的bias被设置成 $ -log((1-\pi)/\pi) $, 其中$\pi=0.01$。 其他层（backbone除外），被设置为均值0，方差0.01
```python
torch.nn.init.normal_(layer.weight, mean=0, std=0.01)
torch.nn.init.constant_(layer.bias, 0)
```
```python
p = torch.sigmoid(predicts)
ce_loss = torch.nn.functional.binary_cross_entropy_with_logits(predicts, targets, reduction="none")
p_t = p * targets + (1 - p) * (1 - targets)
loss = ce_loss * ((1 - p_t) ** gamma)
if alpha >= 0:
    alpha_t = alpha * targets + (1 - alpha) * (1 - targets)
    loss = alpha_t * loss
loss = loss.sum()
loss = loss / max(1, num_matched_based_anchors)
return loss
```

### yolo v3 loss
```python
xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,0:2], from_logits=True)
wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh-raw_pred[...,2:4])
confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) + \
    (1-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,4:5], from_logits=True) * ignore_mask
class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,5:], from_logits=True)
loss = xy_loss + wh_loss + confidence_loss + class_loss
```

### 简单的前向传播卷积实现
```python
def conv_forward(feature, filter, bias, conv_param):
    """
    :param feature: input batch image feature map, shape (batch, img_h, img_w, channel)
    :param filter:  implemented filter, shape (filter_num, filter_h, filter_w, filter_channel)
    :param bias: biases, shape (filter_num)
    :param conv_param: dictionary which contains 'pad', 'stride', ...
    :return: output feature map
    """
    batch, feature_h, feature_w, channel = feature.shape
    filter_num, filter_h, filter_w, filter_channel = filter.shape
    pad = conv_param['pad']
    stride = conv_param['stride']
    feature_pad = np.pad(x, ((0,0), (0,0), (pad,pad),(pad,pad)), 'constant')
    feature_out_h = 1 + (feature_h + 2 * pad - filter_h) // stride)
    feature_out_w = 1 + (feature_w + 2 * pad - filter_w) // stride)
    feature_out = np.zeros((batch, filter_num, feature_out_h, feature_out_w))

    for b in range(barch):
        for f in range(filter_num):
            for i in range(feature_out_h):
                for j in range(feature_out_w):
                    feature_window = feature_pad[b, :, i*stride:i*stride+filter_h, j*stride:j*stride+filter_w].reshape(1, -1)
                    filter_vector = filter[f].reshape(-1, 1)
                    feature_out[b, f, i, j] = feature_window.dot(filter_vector) + bias[f]
    cache = (feature, filter, bias, conv_param)
    return feature_out, cache
```

### 卷积优化
```python
feature_ori = np.zeros((Ho, Wo, 3))
feature = np.zeros((Ho+2*p, Wo+2*p, 3))
feature[p:-p, p:-p, :] = feature_ori
matrix = np.zeros((Ho*Wo, Ci*k*k))
row = 0
for i in range(Ho):
    for j in range(Wo):
        window = feature[i*s:i*s+k, j*s:j*s+k, :].reshape(-1)
        matrix[row] = window
filters = filters.transpose()# (Ci*k*k, Co)
output = np.dot(matrix, filters) # (Ho*Wo, Co)
output = output.reshape(Ho, Wo, Co)
```

### 手写梯度下降
当损失函数为MSE / logloss+sigmoid时：
对特征X求偏导为 $X^T (f(X)-Y)$
(如果有偏置项)对b求偏导为$(f(X)-Y)$
```python
""" 假设有m张图片, 展开后有n个特征向量, 逻辑归回 """
import numpy as np
def prepare_data(batch):
    X = np.zeros((m, n))
    for i in range(m):
        img = cv2.imread(paths[batch][i])
        img = norm(preprocess(img))
        X[i] = img.reshape(-1) # (n,)
    Y = np.ones((m, 1))
    return X, Y

def sigmoid(z):
    return 1 / (1 + np.exp(-z) + 1e-6)

def logit_loss(pred, target, m):
    loss = -target*np.log(pred) - (1-target)*np.log(1-pred)
    return np.sum(loss) / m

def mse_loss(pred, target):
    delta = pred - target
    return np.dot(delta.transpose(), delta) / 2

def forward(X, W):
    """ X (m,n) W (n,1) """
    return np.dot(X, W) + b

def backward(X, A, Y):
    delta = A - Y # (m, 1)
    dW = np.dot(X.transpose(), delta) / m # (n,1)
    db = np.sum(delta) / m                # (1,)
    return dW, db

W = np.random.rand(n, 1)
b = 0
end_loss = 1e-6
for i in range(iteration):
    X, Y = prepare_data(i) # X (m, n), Y (m, 1)
    A = forward(X, W, b) # (m, 1)
    A = sigmoid(A)
    loss = logit_loss(A, Y, m)
    if loss < end_loss:
        break
    dW, db = backward(X, A, Y, m) # (n, 1)
    W = W - lr * dW
    b = b - lr * db
```

### 最小二乘法
假设使用MSE作为损失函数，m个样本，特征维度n
$$ L(a0,a1,...,an) = 1/(2m) \sum_{j=1}^m(f(x0^j,x1^j,...,xn^j) - y^j)^2 $$

f(X)为(m,1)向量，a为(n+1,1)向量，X为(m,n+1)维矩阵，多出来的1是常数项
$$ f(X) = Xa $$

$$ L = 1/2 (Xa-Y)^T(Xa-Y) $$

根据最小二乘法，对损失函数L对a向量求导取0
$$ \frac{\partial L(a)}{\partial a} = X^T(Xa-Y) = 0$$

整理可得
$$ a = (X^T X)^{-1} X^T Y $$

### AUC
ROC曲线: X轴-FPR(false positive rate)，Y轴-TPR(true positive rate)
TPR：在所有实际为阳性的样本中，被正确地判断为阳性之比率。
TPR = TP / (TP + FN)
FPR：在所有实际为阴性的样本中，被错误地判断为阳性之比率。
FPR = FP / (FP + TN)

设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。

AUC: 若随机抽取一个阳性样本和一个阴性样本，分类器正样本的预测概率大于负样本的预测概率之几率.
AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。
mAP受正负样本分布影响明显, AUC几乎不变.
但是在某些场景下，我们会更关注正样本，这时候就要用到 PR 曲线了。例如, 提高二分类的 threshold 就能提高 precision，降低 threshold 就能提高 recall，这时便可观察 PR 曲线，得到最优的 threshold。
```python
def AUC(label, pre):
    # label = [1,0,0,0,1,0,1,0]
    # pre = [0.9, 0.8, 0.3, 0.1, 0.4, 0.9, 0.66, 0.7]
    pos = [i for i in range(len(label)) if label[i] == 1]
    neg = [i for i in range(len(label)) if label[i] == 0]
    auc = 0
    # AUC的含义就是所有穷举所有的正负样本对，
    # 如果正样本的预测概率大于负样本的预测概率，+１
    # 如果正样本的预测概率等于负样本的预测概率，+0.5
    # 如果正样本的预测概率小于负样本的预测概率，+0
    for i in pos:
        for j in neg:
            if pre[i] > pre[j]:
                auc += 1
            elif pre[i] == pre[j]:
                auc += 0.5

    return auc / (len(pos)*len(neg))
```

### kmeans
算法流程:
1. 随机生成k个质心
while 收敛或达到最大迭代次数:
    2. 分别计算每一个样本与k个质心的距离
    3. 每个样本归类到距离最近质心
    4. 基于归类样本更新质心坐标

缺点:
质心的初始位置和数据的分布很大程度影响了算法的精准度和收敛时间。更严重的是，在某些情况下，质心会被一小簇数据“欺骗”，从而陷入到局部最优解，无法达到全局最优。

yolov3 kmeans
```python
def kmeans(self, X, k, dist=np.median):
    """X: (n, 4) bboxes"""
    n = len(X)
    prev_cls = np.zeros((n,))
    # init k centers. replace=False no repeat element
    centers = X[np.random.choice(n, k, replace=False)] # (k, 4)
    while True:
        # distances = np.sqrt(np.sum((X[:,None,:]-centers[:,None,:])**2, axis=-1)) # (n, k)
        distances = 1 - self.iou(X, centers) # (n, k)
        curr_cls = np.argmin(distances, axis=1) # (n,)
        # centers won't change
        if (prev_cls == curr_cls).all():
            break
        # update centers coordinates
        for i in range(k):
            centers[i] = dist(X[curr_cls == i], axis=0)
        prev_cls = curr_cls

    return centers
```

#### knn python 实现
```python
def knn_np(sample, dataset, k):
    """ sample.shape (1, m), dataset.shape (n, m) """
    dists = (dataset - sample) ** 2 # (n, m)
    dists = np.sum(dists, axis=1)
    order = np.argsort(dists)
    return order[:k]

def knn(sample, dataset, k):
    """ dataset.shape (n, m) n个样本每个样本m个特征 """
    n = len(dataset)
    if n == 0:
        return None
    m = len(dataset[0])
    if m == 0:
        return None
    def distance(sample1, sample2):
        dist = 0
        for j in range(m):
            dist += (sample1[j] - sample2[j])**2
        return dist
    dists = []
    for i in range(n):
        dist = distance(sample, dataset[i])
        dists.append((i, dist))
    dists = sorted(dists, key=lambda ele:ele[1])
    matches = []
    for i in range(k):
        matches.append(dists[i])
    return matches


if __name__ == '__main__':
    dataset = [[1,1,1],[2,2,2],[3,3,3],[4,4,4]]
    sample = [2,2,3]
    matches = knn(sample, dataset, 2)
    print(matches)
```

### Opencv 双线性插值
参考:
https://geek-docs.com/opencv/opencv-examples/bilinear-interpolation.html
双线性插值是opencv resize 默认方法,折中来说具有较好速度与图像质量.
1. 生成全黑的放大图像的矩阵
2. 查找放大图像每个点对应的原图像坐标. 设放大后图像x', y', 横纵轴放大率均为a, 原图像坐标为 x'/a, y'/a
3. 寻找原图像周围4领域像素点, (x,y), (x+1,y), (x,y+1), (x+1,y+1)
4. 求4个点到x'/a, y'/a距离, dx = x'/a - x, dy = y'/a - y
5. 则放大图像像素值为
$$ I'(x',y') = (1-dx)(1-dy)I(x,y) + dx(1-dy)I(x+1,y) + (1-dx)dyI(x,y+1) + dxdyI(x+1,y+1) $$

```python
import cv2
import numpy as np

def bl_interpolate(img, ax=1., ay=1.):
    H, W, C = img.shape
    aH = int(ay * H)
    aW = int(ax * W)
    # get position of resized image
    y = np.tile(np.arange(aH), (aW, 1)).transpose()
    x = np.tile(np.arange(aW), (aH, 1))
    # get position of original position
    y = (y / ay)
    x = (x / ax)
    ix = np.floor(x).astype(np.int)
    iy = np.floor(y).astype(np.int)
    ix = np.minimum(ix, W-2)
    iy = np.minimum(iy, H-2)
    # get distance
    dx = x - ix
    dy = y - iy
    dx = np.repeat(np.expand_dims(dx, axis=-1), 3, axis=-1)
    dy = np.repeat(np.expand_dims(dy, axis=-1), 3, axis=-1)
    # interpolation
    out = (1-dx) * (1-dy) * img[iy, ix] + dx * (1 - dy) * img[iy, ix+1] + \
          (1 - dx) * dy * img[iy+1, ix] + dx * dy * img[iy+1, ix+1]
    out = np.clip(out, 0, 255)
    out = out.astype(np.uint8)

    return out

img = cv2.imread("filepath").astype(np.float)
out = bl_interpolate(img, ax=1.5, ay=1.5)
cv2.imshow("result", out)
cv2.waitKey(0)
```

### 中值滤波
```python
def medianBlur(img_3c, kernel, padding_way='ZERO'):
    # kernel size need 3, 5, 7, 9....
    paddingSize = kernel // 2
    height, width, channel = img_3c.shape

    # 假设输入,如下矩阵,5x5
    # [[2 6 3 4 7]
    #  [6 1 7 1 5]
    #  [4 6 7 3 3]
    #  [3 1 8 8 6]
    #  [2 4 8 0 7]]

    # 创建用于输出的矩阵
    matOut = np.zeros((height, width, 3), dtype=img_3c.dtype)
    for c in range(channel):
        img = img_3c[:, :, c]
        matBase = np.zeros((height + paddingSize * 2, width + paddingSize * 2), dtype=img.dtype)

        # 创建一个添加了padding的矩阵,初始值为0
        # 如果kernel的大小为3,所以从5x5变成了7x7
        # [[0 0 0 0 0 0 0]
        #  [0 0 0 0 0 0 0]
        #  [0 0 0 0 0 0 0]
        #  [0 0 0 0 0 0 0]
        #  [0 0 0 0 0 0 0]
        #  [0 0 0 0 0 0 0]
        #  [0 0 0 0 0 0 0]]

        matBase[paddingSize:-paddingSize, paddingSize:-paddingSize] = img
        # 将原值写入新创建的矩阵当中
        #[[0 0 0 0 0 0 0]
        # [0 2 6 3 4 7 0]
        # [0 6 1 7 1 5 0]
        # [0 4 6 7 3 3 0]
        # [0 3 1 8 8 6 0]
        # [0 2 4 8 0 7 0]
        # [0 0 0 0 0 0 0]]

        if padding_way is 'ZERO':
            pass
        elif padding_way is 'REPLICA':
            for i in range(paddingSize):
                matBase[i, paddingSize:-paddingSize] = img[0, :]
                matBase[-(1 + i), paddingSize:-paddingSize] = img[-1, :]
                matBase[paddingSize:-paddingSize, i] = img[:, 0]
                matBase[paddingSize:-paddingSize, -(1 + i)] = img[:, -1]
                # 通过REPLICA后的矩阵,讲四个边补齐
                #[[0 2 6 3 4 7 0]
                # [2 2 6 3 4 7 7]
                # [6 6 1 7 1 5 5]
                # [4 4 6 7 3 3 3]
                # [3 3 1 8 8 6 6]
                # [2 2 4 8 0 7 7]
                # [0 2 4 8 0 7 0]]

        # 这里是遍历矩阵的每个点
        for x in range(height):
            for y in range(width):
                # 获取kernel X kernel 的内容,并转化成队并列
                line = matBase[x:x + kernel, y:y + kernel].flatten()
                # 队列排序处理.
                line = np.sort(line)
                # 取中间值赋值
                matOut[x, y, c] = line[(kernel * kernel) // 2]
    return matOut
```


### mean shift 聚类流程：
mean shift就是沿着密度上升的方向寻找同属一个簇的数据点。图像分割、图像跟踪，需要加入核函数。
1. 在未被标记的数据点中随机选择一个点作为中心center；
2. 找出离center距离在bandwidth之内的所有点，记做集合M，认为这些点属于簇c。同时，把这些求内点属于这个类的概率加1，这个参数将用于最后步骤的分类
3. 以center为中心点，计算从center开始到集合M中每个元素的向量，将这些向量相加，得到向量shift。
4. center = center+shift。即center沿着shift的方向移动，移动距离是||shift||。
5. 重复步骤2、3、4，直到shift的大小很小（就是迭代到收敛），记住此时的center。注意，这个迭代过程中遇到的点都应该归类到簇c。
6. 如果收敛时当前簇c的center与其它已经存在的簇c2中心的距离小于阈值，那么把c2和c合并。否则，把c作为新的聚类，增加1类。
6. 重复1、2、3、4、5直到所有的点都被标记访问。
7. 分类：根据每个类，对每个点的访问频率，取访问频率最大的那个类，作为当前点集的所属类。
https://github.com/zziz/mean-shift

### 计算理论感受野
1. 依次列出每个卷积层的[filter_size 卷积核大小, stride 步长], 如果同时想计算每层的大小需要补充 [padding 填充]
2. 倒推计算卷积层感受野，从网络的最后一层逐层递推到该层。如下图，计算第三层实心点的理论感受野，先计算该点对应第二层的感受野，再计算对应第一层的感受野。（1，2，3层特征图大小6*6，padding为1，stride为1）

```python
receptive_field = 1
for layer in reversed(range(layernum)):
    filter_size, stride, _ = net[layer]
    receptive_field = ((receptive_field - 1) * stride) + filter_size
```

### Huffman 编码

- 是一种文件，图像无损压缩的方法。
- 核心思想：出现频次较多的符号使用较短的编码，出现频次较少的符号使用较长的编码

算法流程
1. 统计符号出现频率
2. 根据频率建立小顶堆(基于频率)，存储HeapNode
3. 依次heappop()出当前堆中最小的两个Node合并，建立二叉树
4. 为二叉树每个节点01编码，左边为0，右边为1

以如下字符串为例，从下往上基于频率合并节点，建立得到二叉树如图，父节点的值为左右子节点的和。左节点编码为0，右节点为1，右节点大于左节点。
```
sample = "A"*40+"B"*20+"C"*16+"D"*11+"E"*7+"F"*4+"G"*2
```

![20200502_131009_22](assets/20200502_131009_22.png)

```python
import heapq
from typing import Dict

class HuffmanCoding():
    def __init__(self):
        self.heap = []
        self.char2coding = {}
        self.coding2char = {}

    def freqence_calculate(self, compressed_str: str):
        """O(n)"""
        freq = {}
        for char in compressed_str:
            freq[char] = 1 if char not in freq else freq[char]+1
        return freq

    def build_heap(self, freq: Dict[str,int]):
        """O(n)"""
        for key in freq:
            node = HeapNode(key, freq[key])
            heapq.heappush(self.heap, node)

    def merge_nodes(self):
        """O(nlogn)"""
        while len(self.heap) > 1:
            node1 = heapq.heappop(self.heap)
            node2 = heapq.heappop(self.heap)
            merge_node = HeapNode(None, node1.freq+node2.freq)
            merge_node.left = node1
            merge_node.right = node2
            heapq.heappush(self.heap, merge_node)

    def encoding(self):
        def helper(node, coding):
            if node == None:
                return
            if node.char != None:
                self.char2coding[node.char] = coding
                self.coding2char[coding] = node.char
            helper(node.left, coding+"0")
            helper(node.right, coding+"1")

        root = heapq.heappop(self.heap)
        helper(root, "")


class HeapNode():
    def __init__(self, char, freq):
        self.char = char
        self.freq = freq
        self.left = None
        self.right = None

    def __lt__(self, other):
        """for comparison in heaq push and pop"""
        return self.freq < other.freq


if __name__ == "__main__":
    sample = "A"*40+"B"*20+"C"*16+"D"*11+"E"*7+"F"*4+"G"*2
    huffman_coding = HuffmanCoding()
    freq = huffman_coding.freqence_calculate(sample)
    huffman_coding.build_heap(freq)
    huffman_coding.merge_nodes()
    huffman_coding.encoding()

    size_cnt = 0
    for key in sorted(huffman_coding.char2coding.keys()):
        code = huffman_coding.char2coding[key]
        print("{}: {}".format(key, code))
        size_cnt += freq[key] * len(code)

    print("before compress: {}".format(len(sample)*(len(bin(len(freq)))-2)))
    print("after compress: {}".format(size_cnt))
```
